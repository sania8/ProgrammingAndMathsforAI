{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870fe943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "def load_image(dataset_dir, size=(200,200)):\n",
    "    X1=[]   # list to store the image data\n",
    "    y1=[]   # list to store the labels of the image dataset\n",
    "    #there are two folders in my dataset \"abnormal->1\" adn \"normal->0\"\n",
    "    classes={\n",
    "        \"normal\" :0,\n",
    "        \"abnormal\": 1\n",
    "    }\n",
    "    # entering into the each class inside the folder\n",
    "    for class_name, class_label in classes.items():\n",
    "        folder = os.path.join(dataset_dir,class_name)\n",
    "        image_paths = glob.glob(folder+\"/*.png\")\n",
    "        for path in image_paths:\n",
    "            img = Image.open(path)\n",
    "            # converting images to grayscale\n",
    "            img = img.convert(\"L\")  # using this method converting all the images to greyscale images\n",
    "            #resizing all images\n",
    "            img = img.resize(size)\n",
    "            #converting all images to array\n",
    "            arr = np.array(img, dtype=np.float32)/255.0\n",
    "            #flattening all the images\n",
    "            arr = arr.flatten()\n",
    "            X1.append(arr)\n",
    "            y1.append(class_label)\n",
    "    X = np.array(X1)\n",
    "    Y = np.array(y1)\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e2b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = load_image(\"spectrogramprocessedata/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a71f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_ratio=0.2):\n",
    "    N = len(X)\n",
    "    idx = np.arange(N)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    split = int(N * (1 - test_ratio))\n",
    "\n",
    "    train_idx = idx[:split]\n",
    "    test_idx  = idx[split:]\n",
    "\n",
    "    return X[train_idx], y[train_idx], X[test_idx], y[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b230695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(X, Y, test_ratio=0.2)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57afa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Suppose majority = class 1, minority = class 0\n",
    "smote = SMOTE(sampling_strategy=0.7, random_state=42)  # minority will be 70% of majority\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Zeros:\", np.sum(y_train_balanced == 0))\n",
    "print(\"Ones :\", np.sum(y_train_balanced == 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfafdac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.W = np.random.randn(in_dim, out_dim)*0.01\n",
    "        self.b = np.zeros((out_dim,))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x @ self.W + self.b\n",
    "\n",
    "    def backward(self, grad_out, l2=0.0):\n",
    "        self.dW = self.x.T @ grad_out + l2*self.W\n",
    "        self.db = np.sum(grad_out, axis=0)\n",
    "        return grad_out @ self.W.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b5b8e",
   "metadata": {},
   "source": [
    "class ReLU:\n",
    "    def forward(self, x):\n",
    "        self.mask = (x > 0)\n",
    "        return x * self.mask\n",
    "\n",
    "    def backward(self, grad_out):\n",
    "        return grad_out * self.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0fec9e",
   "metadata": {},
   "source": [
    "def softmax(z):\n",
    "    z = z - np.max(z, axis=1, keepdims=True)\n",
    "    exp = np.exp(z)\n",
    "    return exp / np.sum(exp, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy(pred, y):\n",
    "    N = y.shape[0]\n",
    "    p = pred[range(N), y]\n",
    "    return -np.mean(np.log(p + 1e-12))\n",
    "\n",
    "def softmax_backward(pred, y):\n",
    "    grad = pred.copy()\n",
    "    grad[np.arange(len(y)), y] -= 1\n",
    "    return grad / len(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd02481b",
   "metadata": {},
   "source": [
    "class Dropout:\n",
    "    def __init__(self, p=0.2):\n",
    "        self.p = p\n",
    "        self.mask = None\n",
    "        self.training = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            keep = 1 - self.p\n",
    "            self.mask = (np.random.rand(*x.shape) < keep) / keep\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x  # no scaling needed (inverted dropout)\n",
    "\n",
    "    def backward(self, grad_out):\n",
    "        if self.training:\n",
    "            return grad_out * self.mask\n",
    "        else:\n",
    "            return grad_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae589c1f",
   "metadata": {},
   "source": [
    "class SimpleNN:\n",
    "    def __init__(self, input_dim, hidden_dim=128, output_dim=2):\n",
    "        self.l1 = Linear(input_dim, hidden_dim)\n",
    "        self.a1 = ReLU()\n",
    "        self.l2 = Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z1 = self.l1.forward(x)\n",
    "        a1 = self.a1.forward(z1)\n",
    "        z2 = self.l2.forward(a1)\n",
    "        return z2\n",
    "\n",
    "    def backward(self, grad, l2=0.0):\n",
    "        grad = self.l2.backward(grad, l2=l2)\n",
    "        grad = self.a1.backward(grad)\n",
    "        grad = self.l1.backward(grad, l2=l2)\n",
    "        return grad\n",
    "\n",
    "    def update(self, lr):\n",
    "        # Update parameters of BOTH Linear layers\n",
    "        for layer in [self.l1, self.l2]:\n",
    "            layer.W -= lr * layer.dW\n",
    "            layer.b -= lr * layer.db\n",
    "\n",
    "    def predict(self, X):\n",
    "        logits = self.forward(X)\n",
    "        probs = softmax(logits)\n",
    "        return np.argmax(probs, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def confusion_matrix(y_true, y_pred, num_classes=2):\n",
    "    cm = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[t, p] += 1\n",
    "    return cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes=['normal', 'abnormal']):\n",
    "    plt.imshow(cm, cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    # write numbers inside boxes\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a445dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1023a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "def plot_metrics(history):\n",
    "    epochs = range(1, len(history[\"loss\"])+1)\n",
    "    \n",
    "    plt.figure(figsize=(16,5))\n",
    "    \n",
    "    # Loss\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.plot(epochs, history[\"loss\"], label=\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss vs Epoch\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
    "    plt.plot(epochs, history[\"test_acc\"], label=\"Test Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy vs Epoch\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Precision / Recall / F1\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(epochs, history[\"precision\"], label=\"Precision\")\n",
    "    plt.plot(epochs, history[\"recall\"], label=\"Recall\")\n",
    "    plt.plot(epochs, history[\"f1\"], label=\"F1\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Precision / Recall / F1 vs Epoch\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def train(model, X_train, y_train, X_test, y_test, lr=0.01, epochs=20, l2=0.0):\n",
    "\n",
    "    # Storage dictionary for plots\n",
    "    history = {\n",
    "        \"loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_acc\": [],\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"f1\": []\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ----- Forward -----\n",
    "        logits = model.forward(X_train)\n",
    "        probs = softmax(logits)\n",
    "\n",
    "        # ----- Loss -----\n",
    "        loss = cross_entropy(probs, y_train)\n",
    "        loss += (l2/2) * (np.sum(model.l1.W**2) + np.sum(model.l2.W**2))\n",
    "\n",
    "        # ----- Backward -----\n",
    "        grad = softmax_backward(probs, y_train)\n",
    "        model.backward(grad, l2=l2)\n",
    "\n",
    "        # ----- Update -----\n",
    "        model.update(lr)\n",
    "\n",
    "        # ----- Train Accuracy -----\n",
    "        train_preds = model.predict(X_train)\n",
    "        train_acc = accuracy(y_train, train_preds)\n",
    "\n",
    "        # ----- Test Accuracy -----\n",
    "        test_preds = model.predict(X_test)\n",
    "        test_acc = accuracy(y_test, test_preds)\n",
    "\n",
    "        # ---- Classification Metrics (Test Set) ----\n",
    "        prec = precision_score(y_test, test_preds, average='macro')\n",
    "        rec  = recall_score(y_test, test_preds, average='macro')\n",
    "        f1   = f1_score(y_test, test_preds, average='macro')\n",
    "\n",
    "        # Save to history for plotting\n",
    "        history[\"loss\"].append(loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"test_acc\"].append(test_acc)\n",
    "        history[\"precision\"].append(prec)\n",
    "        history[\"recall\"].append(rec)\n",
    "        history[\"f1\"].append(f1)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}  Loss={loss:.4f}  \"\n",
    "              f\"TrainAcc={train_acc:.4f}  TestAcc={test_acc:.4f}  \"\n",
    "              f\"Prec={prec:.4f}  Recall={rec:.4f}  F1={f1:.4f}\")\n",
    "\n",
    "    # ===== FINAL EVALUATION =====\n",
    "    final_train_preds = model.predict(X_train)\n",
    "    final_test_preds = model.predict(X_test)\n",
    "\n",
    "    final_train_acc = accuracy(y_train, final_train_preds)\n",
    "    final_test_acc  = accuracy(y_test, final_test_preds)\n",
    "\n",
    "    print(\"\\n=== Final Accuracy ===\")\n",
    "    print(f\"Train Accuracy : {final_train_acc:.4f}\")\n",
    "    print(f\"Test Accuracy  : {final_test_acc:.4f}\")\n",
    "\n",
    "    # FIX: final_preds â†’ final_test_preds\n",
    "    cm = confusion_matrix(y_test, final_test_preds)\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "    plot_confusion_matrix(cm)\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape, y_test.shape)  # should be (num_samples, num_features), (num_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b1ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN(input_dim=X_train.shape[1], hidden_dim=400, output_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ede19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(\n",
    "    model, \n",
    "    X_train, y_train, \n",
    "    X_test, y_test,\n",
    "    lr=0.001,       # learning rate\n",
    "    epochs=70,      # number of epochs\n",
    "    l2=0.00      # L2 regularization strength\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f350f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history[\"test_acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e75abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Your test accuracy values\n",
    "test_acc = [0.5300859598853869, 0.5310410697230181, 0.5396370582617, 0.5434574976122254, \n",
    "            0.5530085959885387, 0.5606494746895893, 0.562559694364852, 0.5663801337153773, \n",
    "            0.5673352435530086, 0.5682903533906399, 0.5692454632282713, 0.5730659025787965, \n",
    "            0.5768863419293219, 0.5778414517669532, 0.5787965616045845, 0.5816618911174785, \n",
    "            0.5864374403056352, 0.5893027698185291, 0.5912129894937918, 0.5921680993314231, \n",
    "            0.5950334288443171, 0.5912129894937918, 0.5950334288443171, 0.5988538681948424, \n",
    "            0.5998089780324737, 0.5998089780324737, 0.6045845272206304, 0.6055396370582617, \n",
    "            0.6026743075453678, 0.6026743075453678, 0.6026743075453678, 0.606494746895893, \n",
    "            0.6103151862464183, 0.6103151862464183, 0.6131805157593123, 0.6150907354345749, \n",
    "            0.6150907354345749, 0.6189111747851003, 0.6198662846227316, 0.6198662846227316, \n",
    "            0.6246418338108882, 0.6255969436485196, 0.6255969436485196, 0.6275071633237822, \n",
    "            0.6275071633237822, 0.6313276026743075, 0.6303724928366762, 0.6313276026743075, \n",
    "            0.6322827125119389, 0.6322827125119389, 0.6303724928366762, 0.6313276026743075, \n",
    "            0.6332378223495702, 0.6332378223495702, 0.6361031518624641, 0.6389684813753582, \n",
    "            0.6399235912129895, 0.6437440305635148, 0.6456542502387774, 0.6427889207258835, \n",
    "            0.6437440305635148, 0.6437440305635148, 0.6456542502387774, 0.6456542502387774, \n",
    "            0.6456542502387774, 0.6446991404011462, 0.6446991404011462, 0.6456542502387774, \n",
    "            0.6456542502387774, 0.6446991404011462]\n",
    "\n",
    "# Epochs\n",
    "epochs = np.arange(1, len(test_acc)+1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(epochs, test_acc, marker='o', linestyle='-', color='b', label='Test Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Test Accuracy vs Epoch\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde0322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training progress\n",
    "plot_metrics(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e7114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "augment = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2)\n",
    "])\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define augmentation pipeline (no rotation)\n",
    "augment = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),  # added vertical flip\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.9, 1.0))  # adjust size as needed\n",
    "])\n",
    "\n",
    "input_dir = 'spectrogramprocessedata/abnormal'       # folder with original abnormal images\n",
    "output_dir = 'spectrogramprocessedata/aug1_abnormal'  # folder to save augmented images\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "num_augmentations = 3  # how many augmented copies per original image\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_path = os.path.join(input_dir, filename)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Save the original image to the augmented folder as well\n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        img.save(os.path.join(output_dir, f\"{base_name}_orig{ext}\"))\n",
    "        \n",
    "        # Generate augmented copies\n",
    "        for i in range(num_augmentations):\n",
    "            aug_img = augment(img)\n",
    "            aug_img.save(os.path.join(output_dir, f\"{base_name}_aug{i}{ext}\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
